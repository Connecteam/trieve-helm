apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: server-pdb
spec:
  minAvailable: "25%"
  selector:
    matchLabels:
      app.kubernetes.io/name: server
      app.kubernetes.io/instance: {{ .Release.Name }}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: server
  labels:
    app.kubernetes.io/name: server
    app.kubernetes.io/instance: {{ .Release.Name }}
spec:
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: server
      app.kubernetes.io/instance: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: server
        app.kubernetes.io/instance: {{ .Release.Name }}
    spec:
      nodeSelector:
        cloud.google.com/gke-spot: "true"
      terminationGracePeriodSeconds: 10
      serviceAccountName: {{ .Values.gcloud.serviceAccountName }}
      containers:
      - name: server
        image: {{ printf "%s:%s" "trieve/server" .Values.containers.server.tag }}
        livenessProbe:
          httpGet:
            path: "/api/health"
            port: 8090
        readinessProbe:
          httpGet:
            path: "/api/health"
            port: 8090
        ports:
          - containerPort: 8090
        securityContext:
          capabilities:
            add: ["SYS_PTRACE"]
        envFrom:
          - configMapRef:
              name: trieve-server-config
      - name: cloud-sql-proxy
        # It is recommended to use the latest version of the Cloud SQL Auth Proxy
        # Make sure to update on a regular schedule!
        image: gcr.io/cloud-sql-connectors/cloud-sql-proxy:2.8.0
        args:
          - "--structured-logs"
          - "--auto-iam-authn"
          # Replace DB_PORT with the port the proxy should listen on
          - "--port=5432"
          - {{ .Values.gcloud.cloudSqlProxyName }}
        securityContext:
          # The default Cloud SQL Auth Proxy image runs as the
          # "nonroot" user and group (uid: 65532) by default.
          runAsNonRoot: true
        # You should use resource requests/limits as a best practice to prevent
        # pods from consuming too many resources and affecting the execution of
        # other pods. You should adjust the following values based on what your
        # application needs. For details, see
        # https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
        resources:
          requests:
            # The proxy's memory use scales linearly with the number of active
            # connections. Fewer open connections will use less memory. Adjust
            # this value based on your application's requirements.
            memory: "1Gi"
            # The proxy's CPU use scales linearly with the amount of IO between
            # the database and the application. Adjust this value based on your
            # application's requirements.
            cpu:    "100m"
